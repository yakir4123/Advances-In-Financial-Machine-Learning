{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Part 2 - Modelling\n",
    "## Chapter 6 - Ensemble Methods"
   ],
   "id": "828595c0d3f993ab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 6.1 Why is bagging based on random sampling with replacement? Would bagging still reduce a forecast’s variance if sampling were without replacement?",
   "id": "6081216dc36ea9aa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Sampling with replacement introduces more **diversity** among the models trained on different bootstrapped samples. Each model might see a slightly different version of the data, leading to varied models that make different errors on different parts of the input space. When these models are averaged (in the case of regression) or voted upon (in the case of classification), the errors tend to cancel each other out, leading to reduced variance.\n",
    "\n",
    "If sampling without replacement were used, the bootstrapped samples would be more similar to the original dataset or identical to it if the sample size equals the dataset size. This would reduce the benefit of aggregation because the individual models would be very similar to a single model trained on the entire dataset.\n",
    "\n",
    "Bagging could still reduce variance to some extent with sampling without replacement, but the reduction would be less effective. The key to bagging’s success lies in the diversity of the models. Without replacement, the lack of sufficient diversity among models means that the average prediction would not benefit as much from the error cancellation effect, leading to higher variance compared to the standard bagging approach."
   ],
   "id": "2fc7e9f4422fbf99"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 6.2 Suppose that your training set is based on highly overlap labels (i.e., with low uniqueness, as defined in Chapter 4).\n",
    "#### 6.2 (a) Does this make bagging prone to overfitting, or just ineffective? Why?"
   ],
   "id": "2c19fb8fe0d95b7e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Mostly ineffective, because the data is highly overlap than the draws are not IID, makes the draws very similar to each other, leads to $\\rho\\rightarrow 1$, from the equation in page 95 it doesn't change the variance of the ensemble model. ",
   "id": "bdac0ac12fd0f57e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 6.2 (b) Is out-of-bag accuracy generally reliable in financial applications? Why?",
   "id": "6fc8bb6306eea93d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "That depends on many reasons, as for our subject, OOB may not be the best reliable because even though the model didn't see these samples before it may be very similar because of high dependency between In and Out of samples which makes them virtually In samples ",
   "id": "926a2c7d55e54259"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 6.3 Build an ensemble of estimators, where the base estimator is a decision tree.",
   "id": "d346bb7d5269dba3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 6.3 (a) How is this ensemble different from an RF?\n",
    "The key difference with\n",
    "bagging is that random forests incorporate a second level of randomness: When\n",
    "optimizing each node split, only a random subsample (without replacement) of the\n",
    "attributes will be evaluated, with the purpose of further decorrelating the estimators."
   ],
   "id": "2313537930df3240"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 6.3 (b) Using sklearn, produce a bagging classifier that behaves like an RF. What parameters did you have to set up, and how?",
   "id": "fdadd444c9992d46"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifier = DecisionTreeClassifier(\n",
    "    criterion='entropy',\n",
    "    max_features='auto',\n",
    "    class_weight='balanced'\n",
    ")\n",
    "bagging_classifier = BaggingClassifier(\n",
    "    estimator=classifier,\n",
    "    n_estimators=1000,\n",
    "    bootstrap=True,\n",
    "    oob_score=True,\n",
    ")                                                                              ### 6.4 "
   ],
   "id": "a880e5e36101b640"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 6.4 Consider the relation between an RF, the number of trees it is composed of, and the number of features utilized:",
   "id": "9ca07daac2bbde80"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 6.4 (a) Could you envision a relation between the minimum number of trees needed in an RF and the number of features utilized?\n",
    "There is no fixed formula for determining the minimum number of trees based on the number of features, but generally, more features might require more trees to ensure that all important features are considered and that the forest is sufficiently diverse.\n",
    "The minimum number of trees needed depends on the interplay between the number of features, the complexity of the problem, and the desired stability of the model.\n",
    "\n",
    "#### 6.4 (b) Could the number of trees be too small for the number of features used?\n",
    "Yes, If the number of features is sufficient big enough and uncorrelated than there has to be a minimum number of trees to use them all. \n",
    "\n",
    "#### 6.4 (c) Could the number of trees be too high for the number of observations available?\n",
    "Yes, If the number of features is small and with much larger amount of trees there might be duplications of trees."
   ],
   "id": "a84de240f5cad5b6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 6.5 How is out-of-bag accuracy different from stratified k-fold (with shuffling) cross validation accuracy?\n",
    "stratified k-fold give average accurecy of the model from k iterations, but thats correct for any k-fold.\n",
    "The key difference is that stratified maintain the balance of the classes between the training and the test"
   ],
   "id": "26c109cece615cd2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
