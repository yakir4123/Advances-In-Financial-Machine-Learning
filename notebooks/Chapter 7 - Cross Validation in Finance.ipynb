{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Part 2 - Modelling\n",
    "## Chapter 6 - Cross Validation in Finance"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b02f1a1ccc57f7b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "af04bd57adf1d1d8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7.1 Why is shuffling a dataset before conducting k-fold CV generally a bad idea in finance? What is the purpose of shuffling? Why does shuffling defeat the purpose of k-fold CV in financial datasets?\n",
    "\n",
    "Shuffling is bad idea because of data leakage and non IID samples, if we shuffle the data we cant monitor if there is a leakage from our training to the testing model. makes the k fold irrelevant because each test set has similar samples in training set and it may lead to false features discoveries.  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d3c16c5d95ffbe5"
  },
  {
   "cell_type": "markdown",
   "source": "### 7.2 Take a pair of matrices (X, y), representing observed features and labels. These could be one of the datasets derived from the exercises in Chapter 3.",
   "metadata": {
    "collapsed": false
   },
   "id": "68c09139ad259522"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from afml.modelling.ensamble_methods import RandomForestClassifier\n",
    "from afml.data_analyst.financial_data_structures import get_t_events\n",
    "from afml.data_analyst.labels import get_vertical_next_day, get_events_triple_barrier, get_bins, get_daily_vol\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from afml.data_analyst.sample_weights import sample_w_by_return, num_co_events\n",
    "from afml.data_analyst.fractionally_differentiated_features import frac_diff_ffd\n",
    "\n",
    "btc_dollar = pd.read_parquet('../data/dollar-bars-100000000-True.parquet')\n",
    "btc_dollar = btc_dollar[btc_dollar.index > pd.Timestamp('2023-01-01').timestamp() * 1000]\n",
    "btc_dollar = btc_dollar.iloc[:-2]\n",
    "\n",
    "cum_log_prices = np.log(btc_dollar['close']).cumsum()\n",
    "fracdiff_series = frac_diff_ffd(pd.DataFrame(np.log(btc_dollar['close']).cumsum()), 2, tau=1e-5)\n",
    "t0 = get_t_events(fracdiff_series.index.values, fracdiff_series['close'].values,\n",
    "                  float(4 * np.std(fracdiff_series.values)))\n",
    "\n",
    "daily_vol = get_daily_vol(btc_dollar)\n",
    "ms_a_day = 24 * 60 * 60 * 1000\n",
    "num_days = 5\n",
    "t1 = get_vertical_next_day(btc_dollar, t0, num_days * ms_a_day)\n",
    "\n",
    "events = get_events_triple_barrier(\n",
    "    close=btc_dollar.loc[fracdiff_series.index, 'close'],\n",
    "    t0=t0,\n",
    "    tp_scale=2,\n",
    "    sl_scale=2,\n",
    "    target=daily_vol,\n",
    "    min_return=0,\n",
    "    t1=t1,\n",
    ")\n",
    "labels = get_bins(events, btc_dollar['close'], t1)\n",
    "\n",
    "X = pd.DataFrame({\n",
    "    'close': fracdiff_series['close'].loc[labels.index],\n",
    "    'close_lag_1': fracdiff_series['close'].shift(1).loc[labels.index],\n",
    "    'close_lag_2': fracdiff_series['close'].shift(2).loc[labels.index],\n",
    "},\n",
    "    index=labels.index\n",
    ")\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# to avoid leakage\n",
    "# t1_train = t1[t1.index < X_test.index[0]]\n",
    "# \n",
    "# w_return = sample_w_by_return(\n",
    "#         t1=t1_train,\n",
    "#         co_events=num_co_events(X_train.index, t1_train),\n",
    "#         close=btc_dollar['close']\n",
    "#     )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f20b4a06be69bef",
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 7.2 (a) Derive the performance from a 10-fold CV of an RF classifier on (X, y), without shuffling.",
   "id": "e5ae558e9cd6c8f9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-24T16:17:37.492433Z",
     "start_time": "2024-08-24T16:17:34.693832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "scores = []\n",
    "kf = KFold(n_splits=10, shuffle=False)  # 10-fold CV without shuffling\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = labels.loc[train_index, 'bin'], labels.loc[test_index, 'bin']\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the validation fold\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate and store the performance metric\n",
    "    score = accuracy_score(y_test, y_pred)  # Replace with your metric\n",
    "    scores.append(score)\n",
    "\n",
    "# Average performance across the 10 folds\n",
    "mean_performance = np.mean(scores)\n",
    "mean_performance"
   ],
   "id": "59fed11346cc1191",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 7\u001B[0m\n\u001B[0;32m      4\u001B[0m scores \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m      5\u001B[0m kf \u001B[38;5;241m=\u001B[39m KFold(n_splits\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)  \u001B[38;5;66;03m# 10-fold CV without shuffling\u001B[39;00m\n\u001B[1;32m----> 7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m train_index, test_index \u001B[38;5;129;01min\u001B[39;00m kf\u001B[38;5;241m.\u001B[39msplit(\u001B[43mX\u001B[49m):\n\u001B[0;32m      8\u001B[0m     X_train, X_test \u001B[38;5;241m=\u001B[39m X[train_index], X[test_index]\n\u001B[0;32m      9\u001B[0m     y_train, y_test \u001B[38;5;241m=\u001B[39m labels\u001B[38;5;241m.\u001B[39mloc[train_index, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbin\u001B[39m\u001B[38;5;124m'\u001B[39m], labels\u001B[38;5;241m.\u001B[39mloc[test_index, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbin\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "\u001B[1;31mNameError\u001B[0m: name 'X' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 7.2 (b) Derive the performance from a 10-fold CV of an RF on (X, y), with shuffling.",
   "id": "4be1965452d434b6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "scores = []\n",
    "kf = KFold(n_splits=10, shuffle=True)  # 10-fold CV without shuffling\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = labels.loc[train_index, 'bin'], labels.loc[test_index, 'bin']\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the validation fold\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate and store the performance metric\n",
    "    score = accuracy_score(y_test, y_pred)  # Replace with your metric\n",
    "    scores.append(score)\n",
    "\n",
    "# Average performance across the 10 folds\n",
    "mean_performance = np.mean(scores)\n",
    "mean_performance"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 7.2 (c) Why are both results so different?\n",
    "The results are quite similar because I barely use any features! but the results when the data is shuffled is better because there is high leakage means that the test data also \"exist\" in the test data, these leakage is "
   ],
   "id": "741c635d76569602"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a8e98e435c0ee4a9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 7.2 (d) How does shuffling leak information?\n",
    "Because the data samples is not IID, each sample take since we sample it till we decide a label it takes T tick, it's easier to be overlaps between samples between the train set to the test set"
   ],
   "id": "daa7e9803fb3fa94"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 7.3 Take the same pair of matrices (X, y) you used in exercise 2.\n",
    "#### 7.3 (a) Derive the performance from a 10-fold purged CV of an RF on (X, y), with 1% embargo."
   ],
   "id": "42d415ab8b9b13e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a86c6073cc017d7d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 7.3 (b) Why is the performance lower?",
   "id": "b5e0efc1cb13d5ec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "757b361e7400290"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 7.3 (c) Why is this result more realistic?",
   "id": "a83f99d0a892db8b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 7.4 In this chapter we have focused on one reason why k-fold CV fails in financial applications, namely the fact that some information from the testing set leaks into the training set. Can you think of a second reason for CVâ€™s failure?\n",
    "\n",
    "Because financial data is non-stationary and high correlated in time, than even though we use purged and embargo tools, we may see a good result with k-fold CV, but it may be because $S_{k_i}$ and $S_{k_{i+2}}$ that is in the training set are correlated with similar market conditions to the test set $S_{k_{i+1}$"
   ],
   "id": "238044b7b6fe3160"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "4950a73093f43e23"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
